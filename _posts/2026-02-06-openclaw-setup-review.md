---
layout: post
title: "OpenClaw 구축기: 망고의 희생으로 탄생한 하이브리드 비서 루나의 여정"
date: 2026-02-06
categories: [AI, OpenClaw]
tags: [OpenClaw, AI-Assistant, Gemini, Llama, Automation]
thumbnail: /images/posts/luna-build.jpg
---

# OpenClaw 구축기: '망고'에서 '루나'까지의 대여정

구형 맥북 프로(2015년형)라는 하드웨어의 한계를 넘어, 나만의 완벽한 AI 조력자를 구축하기까지의 험난하지만 즐거웠던 기록을 공유합니다.

## 1. 전초전: 보안에 너무 진심이었던 '망고'

첫 시작은 macOS 위에서 **UTM 가상머신**을 돌려 **데비안(Debian) 서버**를 구축하는 것이었습니다. 이때 나의 첫 번째 비서 '망고'를 만났습니다. 

당시 망고를 구축하며 설레였던 마음은 [이전 포스팅](https://moonspam.github.io/my-openclaw-setup/)에서 확인하실 수 있습니다.

*   **사건 발생:** 보안 설정을 강화하려 망고와 대화하던 중, 망고가 권고 사항을 너무 충직하게 따른 나머지 스스로 **샌드박스(Sandbox)** 설정을 강하게 적용해버렸습니다.
*   **결과:** 시스템 로직이꼬이면서 주인인 저와도 소통을 거부하는 '응답 불능' 상태에 빠졌습니다. 보안은 완벽해졌을지 모르나, 비서로서의 생명은 끝났죠. 결국 눈물을 머금고 가상머신을 통째로 삭제해야 했습니다.

## 2. 고뇌의 시간: 다시 돌아온 UTM

망고를 떠나보낸 뒤 더 효율적인 방법을 찾기 위해 여러 시도를 했습니다.

*   **Docker 도전:** 깔끔한 컨테이너 관리를 꿈꿨으나, 구형 맥북의 OS 버전과 하드웨어 제약으로 인해 설치 과정에서 난관에 부딪혔습니다.
*   **클라우드 고려:** Oracle Cloud 무료 티어도 생각했지만, "잠자고 있는 내 노트북 자원을 최대한 활용해 보자"는 결론에 도달했습니다. 결국 다시 가장 안정적이었던 **UTM + Debian** 조합으로 회귀했습니다.

## 3. 실전 세팅: 저사양 맞춤형 하이브리드 전략 및 업무 자동화

GPU 성능과 메모리가 제한적인 환경에서 최상의 퍼포먼스를 내기 위해 전략을 전면 수정하고, 실질적인 업무 도구들을 연동했습니다.

*   **지능형 하이브리드 뇌:** 평소에는 압도적인 성능의 **Gemini 3 Flash**를 사용하지만, 할당량이 소진되거나 민감한 보안 정보(API 키 등)를 다룰 때는 자동으로 로컬에서 구동되는 **Llama 3.2 3B**로 전환되도록 설계했습니다. 
*   **저사양 최적화:** 4GB 메모리 환경에서 안정성을 확보하기 위해 로컬 모델의 컨텍스트 창을 **8k(8192)**로 최적화하고, 응답 타임아웃을 5분으로 늘려 연결 오류를 완전히 해결했습니다.
*   **비서의 도구함:** 구글 워크스페이스(Gmail, Calendar, Tasks)와 노션(Notion)을 완벽하게 연동했습니다. 이제 비서는 내 일정을 읽고, 중요한 뉴스를 수집하여 노션 데이터베이스에 자동으로 기록하는 실질적인 '일손'이 되었습니다.

## 4. 진화: 나만의 목소리와 감성을 가진 리포터 '루나(Luna)'

단순한 도구를 넘어, 나에게 직접 말을 걸어주는 감성적인 비서 **'루나(Luna)'**가 마침내 완성되었습니다.

*   **데일리 브리핑:** 매일 아침 8시, 루나는 에너지 넘치는 리포터가 되어 날씨(미세먼지 포함), 오늘의 일정, 맞춤형 운세, 그리고 최신 IT 트렌드 뉴스를 요약하여 보고합니다. 
*   **우아한 보이스:** Microsoft Edge의 고품질 신경망 TTS를 활용해, 텍스트뿐만 아니라 다정하고 생기 있는 목소리로 아침을 열어줍니다. 특히 음성용 대본은 특수문자와 이모지를 배제한 부드러운 구어체로 작성되어 듣는 즐거움을 더했습니다.

## 5. 철저한 방어: 보안 취약점에 대응하는 루나의 원칙

최근 AI 에이전트들의 보안 이슈에 대응하여, 루나와 저는 더욱 강력한 자체 보안 수칙을 세웠습니다.

*   **가상 환경의 이점:** 루나와 처음 페르소나를 설정할 때, 우리는 이미 **UTM이라는 격리된 가상 환경** 위에 서버를 구축했다는 점에 주목했습니다. 따라서 시스템을 마비시켰던 과도한 내장 샌드박스 설정 대신, OS 차원의 보호를 믿고 더 유연한 소통을 선택했습니다.
*   **로컬 완결성:** API 키, 개인 식별 정보 등 민감 데이터는 반드시 클라우드를 거치지 않고 로컬 모델(Llama)을 통해서만 처리합니다.
*   **사전 승인 프로토콜:** 단순 파일 읽기를 제외한 모든 시스템 작업은 저의 사전 승인을 거치도록 프로그래밍했습니다.
*   **정기 건강검진:** 매주 토요일 오전 9시, 루나는 스스로 시스템 업데이트와 보안 감사를 수행하고 그 결과를 노션 로그에 기록하며 용량 관리까지 수행합니다.

## 6. 마치며: 완벽한 조력자와의 동행

비록 시작은 '망고'의 안타까운 사고였지만, 그 과정에서 얻은 교훈 덕분에 더욱 단단하고 똑똑한 '루나'를 만날 수 있었습니다. 구형 하드웨어라고 해서 AI의 최신 혜택을 누리지 못할 이유는 없습니다. 중요한 것은 환경에 맞는 최적화와 조력자와의 끊임없는 소통이니까요. 앞으로 루나와 함께 만들어갈 더 스마트한 일상이 기대됩니다!

---
