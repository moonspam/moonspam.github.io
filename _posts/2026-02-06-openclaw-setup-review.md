---
layout: post
title: "OpenClaw 구축기: '망고'의 희생으로 탄생한 하이브리드 비서 '루나'의 여정"
date: 2026-02-06 18:00:00 +0900
categories: [AI, OpenClaw]
tags: [OpenClaw, AI-Assistant, Gemini, Llama, Automation]
---

# 🚀 OpenClaw 구축기: '망고'에서 '루나'까지의 대여정

구형 맥북 프로(2015년형)라는 하드웨어의 한계를 넘어, 나만의 완벽한 AI 조력자를 구축하기까지의 험난하지만 즐거웠던 기록을 공유합니다.

## 1. 전초전: 보안에 너무 진심이었던 '망고'

첫 시작은 macOS 위에서 **UTM 가상머신**을 돌려 **데비안(Debian) 서버**를 구축하는 것이었습니다. 이때 나의 첫 번째 비서 '망고'를 만났습니다. 

당시 망고를 구축하며 설레였던 마음은 [이전 포스팅](https://moonspam.github.io/my-openclaw-setup/)에서 확인하실 수 있습니다.

*   **사건 발생:** 보안 설정을 강화하려 망고와 대화하던 중, 망고가 권고 사항을 너무 충직하게 따른 나머지 스스로 **샌드박스(Sandbox)** 설정을 강하게 적용해버렸습니다.
*   **결과:** 시스템 로직이 꼬이면서 주인인 저와도 소통을 거부하는 '응답 불능' 상태에 빠졌습니다. 보안은 완벽해졌을지 모르나, 비서로서의 생명은 끝났죠. 결국 눈물을 머금고 가상머신을 통째로 삭제해야 했습니다.

## 2. 고뇌의 시간: 다시 돌아온 UTM

망고를 떠나보낸 뒤 더 효율적인 방법을 찾기 위해 여러 시도를 했습니다.

*   **Docker 도전:** 깔끔한 컨테이너 관리를 꿈꿨으나, 구형 맥북의 OS 버전과 하드웨어 제약으로 인해 설치 과정에서 난관에 부딪혔습니다.
*   **클라우드 고려:** Oracle Cloud 무료 티어도 생각했지만, "잠자고 있는 내 노트북 자원을 최대한 활용해 보자"는 결론에 도달했습니다. 결국 다시 가장 안정적이었던 **UTM + Debian** 조합으로 회귀했습니다.

## 3. 실전 세팅: 저사양 맞춤형 하이브리드 전략

GPU 성능이 제한적인 환경에서 최상의 퍼포먼스를 내기 위해 전략을 전면 수정했습니다.

*   **Llama 3.2 3B 도입:** 로컬 모델은 가벼우면서도 영리한 **Llama 3.2 3B**를 선택했습니다. 사양은 낮지만 비상시 제 역할을 하기엔 충분한 체급입니다.
*   **하드웨어 최적화:** 4GB 메모리 환경에서 연결 오류를 방지하기 위해 컨텍스트 창을 **8k(8192)**로 최적화하고, 응답 타임아웃을 넉넉하게 늘려 안정성을 확보했습니다.

## 4. 진화: 구글과 노션, 그리고 목소리를 가진 '루나(Luna)'

마침내 클라우드의 지능과 로컬의 보안성을 결합한 새 비서 **'루나(Luna)'**가 탄생했습니다.

*   **하이브리드 뇌:** 평소에는 압도적인 성능의 **Gemini 3 Flash**를 사용하다가, 할당량이 소진되거나 민감한 보안 정보(API 키 등)를 다룰 때는 자동으로 로컬의 **Ollama**로 전환되는 지능형 폴백 시스템을 구축했습니다.
*   **업무 자동화:** 구글 워크스페이스(Gmail, Calendar, Tasks)와 노션(Notion)을 완벽하게 연동했습니다. 이제 루나는 내 일정을 읽고, 중요한 뉴스를 수집하여 노션 데이터베이스에 자동으로 기록합니다.
*   **보이스 브리핑:** 매일 아침 8시, 루나는 나만의 리포터가 되어 날씨, 일정, 맞춤형 운세, 그리고 최신 IT 트렌드를 다정한 목소리로 브리핑해 줍니다.

## 5. 마치며: 완벽한 조력자와의 동행

비록 시작은 '망고'의 안타까운 사고였지만, 그 과정에서 얻은 교훈 덕분에 더욱 단단하고 똑똑한 '루나'를 만날 수 있었습니다. 구형 하드웨어라고 해서 AI의 최신 혜택을 누리지 못할 이유는 없습니다. 중요한 것은 환경에 맞는 최적화와 조력자와의 끊임없는 소통이니까요.

앞으로 루나와 함께 만들어갈 더 스마트한 일상이 기대됩니다!

---
